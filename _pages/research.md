---
layout: single
title: "Research"
permalink: /research/
author_profile: true
---

## Research Statement

My research lies at the intersection of **robust machine learning, uncertainty-aware modeling, and interpretable and trustworthy AI**. I develop theoretically grounded learning frameworks that remain reliable under **noise, outliers, class imbalance, and distributional shift**, with the overarching goal of enabling trustworthy machine learning in high-stakes clinical and biomedical settings.

My early work focused on the design of **robust loss functions *(e.g., RoBoSS loss, Wave loss, Guardian loss, HawkEye loss)* and adaptive weighting mechanisms *(e.g., RAPID weighting scheme)*** for support vector machines, randomized neural networks, and kernel-based learning models. In particular, I introduced principled strategies for jointly addressing noise, outliers, and class imbalance through bounded loss formulations and data-adaptive weighting schemes, enabling stable learning under imperfect real-world data conditions. These contributions established theoretically grounded frameworks for robust tabular learning and were validated across diverse benchmarks and biomedical prediction tasks, resulting in publications in leading venues such as **IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)**, **Pattern Recognition**, **Neural Networks**, and **Applied Soft Computing**.

I further investigated the statistical structure of feature dependencies in tabular data and proposed **copula-based weight initialization for randomized neural networks**, enabling dependency-aware hidden representations and improved generalization. This work addresses a long-standing limitation of randomized neural networks, i.e., the use of fully random, fixed input-to-hidden weights that ignore data distribution and feature relationships. By introducing statistically aligned, dependency-aware initialization, the proposed framework closes this foundational gap and transforms randomized neural networks from purely random feature models into data-informed learning systems. This work was accepted at the **International Conference on Artificial Intelligence and Statistics (AISTATS)**.

Through this line of research, I identified a fundamental limitation of conventional learning systems: their reliance on deterministic point predictions with limited uncertainty characterization and weak density-level interpretability. Such models provide accurate predictions but lack calibrated uncertainty and probabilistic structure, which restricts their reliability and clinical trustworthiness in high-stakes biomedical decision-making.

Motivated by this gap, my recent research has shifted toward **probabilistic and density-aware neural learning frameworks** that integrate statistical modeling with neural architectures to provide principled uncertainty quantification and interpretable predictive structure. In parallel, I investigate **statistical modeling of feature dependencies via copula theory** to capture structured relationships among biomedical variables and to enable dependency-aware probabilistic inference in machine learning systems.

Overall, my research vision is to bridge **statistical learning theory, probabilistic modeling, and neural network methods** to develop machine learning frameworks that are **robust, interpretable, and uncertainty-aware *by design***â€”moving beyond point prediction toward trustworthy, distribution-aware learning systems suitable for deployment in biomedical and scientific domains.

---

## Core Research Themes

- Robust Machine Learning
- Loss Function Design and Robust Optimization  
- Randomized Neural Networks and Kernel Methods    
- Uncertainty-Aware Learning  
- Interpretable and Trustworthy AI  
- Statistical Machine Learning  
- Copula-Based Dependency Modeling  
- Probabilistic Neural Networks  
- Tabular Machine Learning  
- Biomedical and Clinical AI  

---

## Methodological Contributions

My research develops new learning frameworks and theoretical tools to improve **stability, robustness, and generalization** in machine learning systems. Key methodological contributions include:

- Robust loss function design for learning under noise, outliers, and class imbalance  
- Adaptive and data-driven weighting mechanisms for imbalance- and difficulty-aware learning  
- Stable randomized neural networks via spectral regulation and structured initialization  
- Copula-based statistical modeling to capture feature dependencies in learning systems  
- Uncertainty-aware learning frameworks for reliable and calibrated prediction  
- Hierarchical probabilistic neural networks for robust and interpretable prediction  

These methodological advances have been validated across diverse benchmark datasets and biomedical learning scenarios, demonstrating consistent improvements in robustness, stability, and predictive reliability.

---

## Application Focus

I apply my methodological developments primarily to structured and tabular data settings, with emphasis on:

- Biomedical and healthcare data analysis  
- Disease diagnosis and prognosis modeling  
- Clinical decision-support systems  
- Scientific and engineering data modeling  

---

## Current and Future Research Directions

My current research aims to advance **statistically grounded and trustworthy machine learning**, particularly through:

- Dependency-aware neural network initialization and learning  
- Robust and uncertainty-aware randomized neural networks  
- Copula-integrated machine learning models  
- Reliable learning under distributional shift and data uncertainty  

In future work, I aim to develop **interpretable and uncertainty-aware machine learning frameworks for biomedical and scientific applications**, bridging statistical modeling and modern neural learning paradigms.

---
